{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from census import Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Variable Code\n",
    "def get_acs_code(var_select,filepath = '../data/acs_variable_code.csv'):\n",
    "    acs_code_df = pd.read_csv(filepath)\n",
    "    acs_dict = {}\n",
    "    for i in range(len(acs_code_df)):\n",
    "        acs_dict[acs_code_df.loc[i,'Variable Name']] = acs_code_df.loc[i,'Variable Code']\n",
    "\n",
    "    code_list = []\n",
    "    for f in var_select:\n",
    "        code_list.append(acs_dict[f])\n",
    "    return code_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01003_001E', 'B25001_001E']\n"
     ]
    }
   ],
   "source": [
    "code_list = get_acs_code(var_select=['Total Population', 'Total Housing Units'],filepath = '../data/acs_variable_code.csv')\n",
    "print(code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_fips_code(lat, lon):\n",
    "    url = \"https://geo.fcc.gov/api/census/block/find\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    state_fips = data[\"State\"][\"FIPS\"]\n",
    "    state_name = data[\"State\"][\"name\"]\n",
    "    county_fips = data[\"County\"][\"FIPS\"]\n",
    "    county_name = data[\"County\"][\"name\"]\n",
    "    return state_fips,state_name, county_fips, county_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_contents(filename):\n",
    "    \"\"\" Given a filename,\n",
    "        return the contents of that file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # It's assumed our file contains a single line,\n",
    "            # with our API key\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_file = '/Users/caoguangyue/GitHub/Urban-Design-Equity-Metrics/app/census_api_key.txt'\n",
    "api_key = get_file_contents(api_file)\n",
    "c = Census(api_key)\n",
    "# Replace with Input from lat, lng\n",
    "state_fips,state_name, county_fips, county_name = get_fips_code(37.7749, -122.4194)\n",
    "\n",
    "\n",
    "sc_census = c.acs5.state_county_blockgroup(fields= code_list, state_fips = str(state_fips), county_fips = str(county_fips[2::]), blockgroup = '*', year = 2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. Feature engineering\n",
    "# Feature Engineering\n",
    "acs_df = pd.DataFrame(sc_census)\n",
    "acs_df['geoid'] = sc_df['state'] + sc_df['county'] + sc_df['tract'] + sc_df['block group']\n",
    "\n",
    "\n",
    "inv_acs_dict = {v: k for k, v in acs_dict.items()}\n",
    "acs_df.rename(columns=inv_acs_dict, inplace=True)\n",
    "\n",
    "acs_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
